{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "offensive-delight",
   "metadata": {},
   "source": [
    "## IMPORT LIBRARIES AND PACKAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "conditional-tablet",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import cv2\n",
    "from imantics import Mask\n",
    "\n",
    "import os\n",
    "import sys\n",
    "partial_path = os.getcwd().rsplit('/', 1)[0]\n",
    "sys.path.insert(0, f'{partial_path}/src/')\n",
    "\n",
    "from utils import setup_damage_detector, crop_damage_v2\n",
    "import config as cf\n",
    "\n",
    "from detectron2.engine.defaults import DefaultPredictor\n",
    "import shutil\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dramatic-dallas",
   "metadata": {},
   "source": [
    "## REORDER IMAGES IN THE RIGHT FORM (also rotate image according to exif in order to avoid problems with smarthphone photos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "stock-glossary",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL.ExifTags import TAGS\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import ImageOps\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "unlike-excellence",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 43/43 [20:53<00:00, 29.14s/it]\n"
     ]
    }
   ],
   "source": [
    "os.makedirs('../data/test_papers_2.0.0', exist_ok=True )\n",
    "for dam in tqdm(glob.glob('../data/raw_data/*')):\n",
    "    dam_id=os.path.basename(dam)\n",
    "    im_id=0\n",
    "    for im in glob.glob(os.path.join(dam, '*')):\n",
    "        with Image.open(im) as image:\n",
    "            try:\n",
    "                image = ImageOps.exif_transpose(image)\n",
    "            except:\n",
    "                pass\n",
    "            data = list(image.getdata())\n",
    "            image_without_exif = Image.new(image.mode, image.size)\n",
    "            image_without_exif.putdata(data)\n",
    "\n",
    "            image_without_exif.save(f'../data/test_papers_2.0.0/{dam_id}_{im_id}.jpg')\n",
    "        im_id+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "increasing-refrigerator",
   "metadata": {},
   "source": [
    "## IMPORT DAMAGE DETECTION MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "written-lecture",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The checkpoint state_dict contains keys that are not used by the model:\n",
      "  \u001b[35mproposal_generator.anchor_generator.cell_anchors.{0, 1, 2, 3, 4}\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "cfg = setup_damage_detector()\n",
    "predictor = DefaultPredictor(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "square-baseball",
   "metadata": {},
   "source": [
    "## EXTRACT DAMAGES FROM IMAGES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "faced-howard",
   "metadata": {},
   "outputs": [],
   "source": [
    "inpath= '../data/test_papers_2.0.0/'\n",
    "path = os.path.join(inpath, '*')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "superior-cliff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/567 [00:00<?, ?it/s]/home/e3eferri/.conda/envs/color_env/lib/python3.8/site-packages/torch/_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ../aten/src/ATen/native/BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "100%|██████████| 567/567 [04:00<00:00,  2.36it/s]\n"
     ]
    }
   ],
   "source": [
    "damages = []\n",
    "for im in tqdm(glob.glob(path)):\n",
    "    image = cv2.imread(im)\n",
    "    el = im.split('/')\n",
    "    filename = el[-1]\n",
    "    outputs = predictor(image)\n",
    "    pred_classes = outputs[\"instances\"].pred_classes.cpu().numpy()\n",
    "    pred_bboxes = outputs[\"instances\"].pred_boxes.tensor.cpu().numpy()\n",
    "    pred_scores = outputs[\"instances\"].scores.cpu().numpy()\n",
    "    damages.append([im, filename, {cf.CLASSES_KEY_NAME: pred_classes, cf.BOXES_KEY_NAME: pred_bboxes, cf.SCORES_KEY_NAME: pred_scores}])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neither-spotlight",
   "metadata": {},
   "source": [
    "## SAVE RESULTS INTO PICKLE FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "enhanced-flooring",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(damages, columns=[cf.FILEPATH_COL_NAME, cf.FILENAME_COL_NAME, cf.DAMAGES_INFO_COL_NAME])\n",
    "dataset_name = path.split('/')[-1]\n",
    "outdir = os.path.join(cf.SAVE_RESULTS_PATH, f'{dataset_name}.p')\n",
    "df.to_pickle(outdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "according-approach",
   "metadata": {},
   "source": [
    "## LOAD PICKLE "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "painful-petersburg",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_pickle(outdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "sticky-admission",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "social-ethnic",
   "metadata": {},
   "source": [
    "## EXTRACT PATCHES CONTAINING DAMAGES AND SAVE THEM AS FIGURES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "residential-examination",
   "metadata": {},
   "source": [
    "#### version 1: if no damage is found, take the image as a whole"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "global-vienna",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "567it [02:02,  4.61it/s]\n"
     ]
    }
   ],
   "source": [
    "new_path = inpath.replace('2.0.0','2.0.1')\n",
    "\n",
    "os.makedirs(new_path, exist_ok=True)\n",
    "for row in tqdm(df.itertuples()):\n",
    "    #new_path = os.path.join(cf.CROP_DAMAGE_DATA_PATH, row.claim)\n",
    "    if len(row.damages['classes'])>0:\n",
    "        crop_damage_v2(row.path, row.damages, title=row.filename, save=True, outpath=new_path)\n",
    "    else:\n",
    "        shutil.copyfile(row.path, os.path.join(new_path, row.filename))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "becoming-practice",
   "metadata": {},
   "source": [
    "#### version 2: if no damage is found, skip the picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "medieval-processor",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "567it [02:04,  4.56it/s]\n"
     ]
    }
   ],
   "source": [
    "new_path = inpath.replace('2.0.0','2.0.2')\n",
    "os.makedirs(new_path, exist_ok=True)\n",
    "for row in tqdm(df.itertuples()):\n",
    "    #new_path = os.path.join(cf.CROP_DAMAGE_DATA_PATH, row.claim)\n",
    "    if len(row.damages['classes'])>0:\n",
    "        crop_damage_v2(row.path, row.damages, title=row.filename, save=True, outpath=new_path)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-colleague",
   "metadata": {},
   "source": [
    "## CLEAN DATASET BY HAND\n",
    "\n",
    "Go into the folder and remove all the crops of false positives and wrong damage detection (to assure that each index is consistent)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unavailable-authority",
   "metadata": {},
   "source": [
    "# ASSURE CONSISTENT NUMBERING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "engaging-acquisition",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_path = inpath.replace('2.0.0','2.0.1_clean')\n",
    "final_path =new_path.replace('2.0.1_clean', '2.1.0')\n",
    "os.makedirs(final_path, exist_ok=True)\n",
    "damages=set(i.split('/')[-1].split('_')[0] for i in glob.glob(os.path.join(new_path, '*')))\n",
    "dam_id=0\n",
    "for i in damages:\n",
    "    im_id=0\n",
    "    pictures=glob.glob(os.path.join(new_path, f'{i}_*'))\n",
    "    for j in pictures:\n",
    "        shutil.copy(j, os.path.join(final_path, f'{dam_id}_{im_id}.jpg'))\n",
    "        im_id+=1\n",
    "    dam_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "blessed-panic",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = inpath.replace('2.0.0','2.0.2_clean')\n",
    "final_path =new_path.replace('2.0.2_clean', '2.2.0')\n",
    "os.makedirs(final_path, exist_ok=True)\n",
    "damages=set(i.split('/')[-1].split('_')[0] for i in glob.glob(os.path.join(new_path, '*')))\n",
    "dam_id=0\n",
    "for i in damages:\n",
    "    im_id=0\n",
    "    pictures=glob.glob(os.path.join(new_path, f'{i}_*'))\n",
    "    for j in pictures:\n",
    "        shutil.copy(j, os.path.join(final_path, f'{dam_id}_{im_id}.jpg'))\n",
    "        im_id+=1\n",
    "    dam_id+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "abandoned-public",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_path = '../data/test_BDEO'\n",
    "final_path =new_path.replace('BDEO', 'BDEO_remapped')\n",
    "os.makedirs(final_path, exist_ok=True)\n",
    "damages=set(i.split('/')[-1].split('_')[0] for i in glob.glob(os.path.join(new_path, '*')))\n",
    "dam_id=0\n",
    "for i in damages:\n",
    "    im_id=0\n",
    "    pictures=glob.glob(os.path.join(new_path, f'{i}_*'))\n",
    "    for j in pictures:\n",
    "        shutil.copy(j, os.path.join(final_path, f'{dam_id}_{im_id}.jpg'))\n",
    "        im_id+=1\n",
    "    dam_id+=1"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8b8f3989125208fea901a3daa574ecf0772df957395fd275df331599c4a0898c"
  },
  "kernelspec": {
   "display_name": ".conda-color_env",
   "language": "python",
   "name": "conda-env-.conda-color_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
